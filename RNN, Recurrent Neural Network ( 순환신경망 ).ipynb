{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3858793",
   "metadata": {},
   "source": [
    "## RNN, Recurrent Neural Network  (순환신경망 )\n",
    "\n",
    "RNN은 인공신경망의 한 종류로, 유닛간의 연결이 순환적인 구조를 가짐에 따라 순차적인 정보를 모델링 할 수 있는 신경망이다. CNN과 같은 다른 신경망들은 메모리가 없으므로, 시계열 데이터 같은 sequential 한 데이터를 처리하기 위해서는 전체 시퀀스를 하나의 벡터로 넣어줘야 한다. 이런 네트워크를 feed forward network라고 한다. RNN은 이와 반대로 내부 메모리를 가지기 때문에 시퀀드 형태의 입력을 처리 할 수 있다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1125161b",
   "metadata": {},
   "source": [
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbJ21vM%2FbtqP9sUwff4%2FdB5MYlreaFqOBl3KcHKMU0%2Fimg.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "ono to one 모델은 입력과 출력이 1개인 것으로 대표적으로 vanilla Neural Network가 있다.   \n",
    "\n",
    "ono to many 모델은 입력은 1개, 출력은 여러개인 방법으로 대표적인 예로 image captioning(이미지를 단어로 설명하는 기술)이 있다. input으로 이미지가 들어가며, 이미지 내부의 물체들에 대해 여러개의 단어로 변환하여 설명하는 방식으로 진행됨  \n",
    "\n",
    "many to one는 입력이 여러개, 출력은 하나인 방법이다. 대표적인 예로 감성 분류를 들 수 있다. 일련의 텍스트들인 input으로 들어오고 이 것들이 긍정인지 부정인지 분류를 통해 output으로 나오게 된다.   \n",
    "\n",
    "many to many는 두 가지로 나눠지는 데, 전자의 대표적인 것은 번역(Machine Translation)이 있다. 나라마다 언어의 길이나 크기가 다르기 때문에 입력의 크기와 출력의 크기가 다를 수 있다. 후자의 경우 비디오 분류(Video classification)를 예로 들 수 있다.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea98596",
   "metadata": {},
   "source": [
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FXEmoB%2Fbtq2iWJ4jK9%2FHnCtYbogVuJM2ssAgPXCq0%2Fimg.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "RNN은 과거의 정보를 현재에 반영해 학습하도록 설계 되었다. 이 방법을 통해 시간순서로 나열된 데이터를 학습한다. 파라미터w가 있는 함수안에 hiddenstate에 있던 이전 값과 현재 인풋 x를 통해 현재 타임 스텝인 h가 갱신된다. \n",
    "\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FYJIwM%2Fbtq2s0jGNjW%2F5cfgVO7tXKzvv0DXeArkVK%2Fimg.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "주의해야 할 점은 각 시점에서 계산 마다 같은 함수 f와 같은 가중치 w를 사용한다는 것이다. \n",
    "\n",
    "Vanilla RNN에서는 tanh함수를 사용했다. tanh함수는 비선형성을 위해 적용하게 되었는데, 선형함수를 사용하게 되면, 층을 거치면서 크게 변화가 발생하지 않는다. tanh함수는 RNN의 gradient가 최대한 오래 유지할 수 있도록 해주는 역할로 사용된다. \n",
    "\n",
    "$Whh$ 는 h와 h 사이의 파라미터, $Wxh$ 는 x에서 h 사이의 파라미터, $Why$는 h에서 y 사이의 파라미터로 사용됩니다. 여기에 있는 파라미터들은 위에서도 언급했듯이 모든 타임 스텝에서 동일한 값을 가집니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c204c0eb",
   "metadata": {},
   "source": [
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbQpybd%2Fbtq2tsUyTv3%2Fq1tuYvXrjgSxRgZvRx8Gxk%2Fimg.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "계산 그래프에서 같은 노드를 여러번 재사용하면, 역방향 전파동안 d손실과 dW를 계산할 때 경사를 W 행렬로 결국 더하게 된다.모델에 대한 역전파를 생각한다면, 이 타임 스텝 각각으로부터 흐르는 W에 대한 별도의 경사가 있을 거고 W의 최종 경사는 타임스탭 각각 마다의 경사를 모두 더한 것이 될 것이다. 이 전체 훈련 과정을 위한 최종 손실이 개별 손실들의 합이 될 것이다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf90de51",
   "metadata": {},
   "source": [
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FqQZMJ%2Fbtq2qwX2qZa%2FkVi3K4qZCa4LiJVJW8VaR1%2Fimg.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "'hellow'라는 sequence data 주고, 예측하는 예시 이다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
