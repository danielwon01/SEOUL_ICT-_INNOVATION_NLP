{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b12142dc",
   "metadata": {},
   "source": [
    "## CNN \n",
    "\n",
    "영상인식 처리 분야에 있어서 가장 기본이 되는 모델 \n",
    "눈과 뇌에서 처리되는 신경과학적 시각처리 방식에서 고안한 모델 \n",
    "\n",
    "신경망 동작을 처리하기 위하여 합성곱 연산을 이용 \n",
    "CNN 모델에서는 합성곱 연산을 기반으로 각 픽셀이 서로 얼마나 일치하는지 계산하여 그 계산 결과를 활용`\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "<img src=\"https://jylab.github.io/assets/images/cnn/cnn2.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "\n",
    "이미지의 특징을 추출하는 부분과 클래스를 분류하는 부분으로 나눌 수 있다. 특징 추출 영역은 Conv layer와 pooling layer를 여려겹 쌓는 형태로 구성된다. Conv layer는 입력 데이터에 필터를 적용 후 활성화 함수를 반영하는 필수 요소이다. Conv layer 다음에 위치하는 pooling layer는 선택적인 레이어이다. 마지막 부분에는 이미지 분류를 위한 FC레이어가 추가된다. 이미지의 특징을 추출하는 부분과 이미지를 분류하는 부분 사이에 이미지 형태의 데이터를 배열 형태로 만드는 Flatten 레이어가 위치한다. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc54f4e",
   "metadata": {},
   "source": [
    "### FC,Fully Conneted Layer \n",
    "\n",
    "<img src=\"https://blog.kakaocdn.net/dn/MFv6C/btqXFgyDRGq/lG2ivJWQwR1qM7gVAtZG8K/img.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "FC는 벡터들의 연산을 진행, 32x32x3의 이미지를 flatten하게 펴서 3072차원의 벡터로 만든다. 가중치 W(10x3072)를 벡터와 곱하고 activation을 이 layer의 출력값으로 얻는다. 일반적으로 기존의 신경망에서 각 층별 연결에 사용되는 방식. 전결합층 이다. 모든 노드를 연결하므로 수많은 연산이 일어남, CNN 의 특징은 모든 노드를 결합하지 않음으로써 연산량을 줄여 효율성을 높이는 방식 \n",
    "\n",
    "FC 특징 \n",
    "모든 노드를 연결하므로 1차원배열로 표시됨,이미지의 공간정보가 사라짐, 최종 결과값은 분류 결과 도출, 결국 마지막에 도출된 분류결과 Label을 선택하여야 , 최종 결과를 분류하기 위한 기반 정보는 모두 가지고 있어야 분류를 위한 SoftMax 함수를 사용할 수 있음, 필수는 아니며 Convolution Layer 의 결과를 그대로 사용할 수도 있음\n",
    "\n",
    "**FC와 Convolution layer의 차이점은 Convonlution는 기존의 구조를 보존시키다는 것이다. 32x32x3의 이미지지를 flatten시키는 것이 아니라 기존의 이미지 구조를 그대로 유지한다.**\n",
    "\n",
    "* 각 레이어의 입출력 데이터의 형상 유지\n",
    "* 이미지의 공간 정보를 유지하면서 인접 이미지와의 특징을 효과적으로 인식 \n",
    "* 복수의 필터로 이미지의 특징 추출 및 학습 \n",
    "* 추출한 이미지의 특징을 모으고 강화하는 Pooling layer\n",
    "* 필터를 공유 파라미터로 사용하기 때문에, 일반 인공 신경망과 비교하여 학습 파라미터가 적음 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b898f942",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.kakaocdn.net/dn/XS44I/btqYE7GEYMc/BzE6v6k1kohceoewC3iRDK/img.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "합성곱의 가중치는 사진에서 보이는 봐와 같이 파란색의 작은 필터가 가중치가 된다. 필터를 이용해 이미지를 슬라이딩 하면서 공간적으로 내적을 수행하게 된다. \n",
    "필터는 이미지의 깊이 만큼 확장된다. 필터의 높이와 넓이는 기존 이미지를 넘지 않는 선에서 정해질 수 있지만 깊이는 기존 이미지와 동일하게 정해져야 한다. \n",
    "\n",
    "필터가 슬라이딩할 때, Convolution은 이미지의 좌상단부터 시작한다. 필터의 모든 요소를 가지고 내적을 수행하게 되면 하나의 값을 얻게 된다. 합성곱 연산을 수행하는 값들을 다시 output activation map에 해당하는 위치에 저장한다. \n",
    "\n",
    "\n",
    "------\n",
    "\n",
    "Channel,채널  \n",
    "이미지 픽셀 하나하나는 실수, 컬러 사진은 각 픽셀을 RGB 3개의 실수로 표현한 3차원 데이터이다. 컬러 이미지는 3개의 채널로 구성된다. 예를 들어 높이가 30픽셀이고 폭이 30인 컬러사진 데이터의 shape는 (30,30,3)으로 표현 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f7418c",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.kakaocdn.net/dn/llPou/btqYB5P4ohc/q0lYvk9csFdBABeYame6XK/img.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "\n",
    "-----\n",
    "Fitter   \n",
    "필터는 이미지의 특징을 찾아내기 위한 공용 파라미터이다. Filter를 Kernel이라고도 한다.(같은 의미), 필터는 일반적으로 (4,4)나 (3,3)같은 정사각 행렬로 정의된다. CNN에서 학습의 대상은 필터 파라미터이다. 입력 데이터를 지정된 간격으로 순회하며 채널별로 합성곱을 하고 모든 채널의 합성곱의 합을 Feature Map으로 만든다. 필터는 지정된 간격으로 이동하면서 전체 입력데이터와 합성곱하여 Feature Map을 만든다. \n",
    "\n",
    "------\n",
    "\n",
    "합성곱 계층을 다룰 때는 여러 필터로 작업, 필터 마다 다른 특징을 추출하고 싶기 때문이다. 한 layer에서 원하는 만큼 여러개의 필터를 사용할 수 있다. \n",
    "CNN은 Convolution layer의 연속된 형태가 된다. 각각을 쌓아 올리게 되면 Linear layer로 된 Neeural Network가 되고 그 사이에 ReLu 같은 활성화 함수를 넣는다. 각 layer의 출력은 다음 layer의 입력이 되고 각 layer는 여러개의 필터를 가지고 각 필터마다 각각의 출력 map을 만든다. 결국 각 필터들이 계층적으로 학습을 하게 된다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "------\n",
    "<img src=\"https://blog.kakaocdn.net/dn/vxxfq/btqYvdIqP6X/LIjuKWivjZyknWkmlts8AK/img.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec518657",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.kakaocdn.net/dn/btgMpf/btqYurfRzIh/neKbjm9LeqQ38lQ9gQ9k41/img.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "초기 레이어의 필터들은 낮은 수준의 피저들을 표현, 중간 수준에선 더 복잡한 종류의 피쳐들을 얻게 된다. 그 뒤 더 높은 수준의 피쳐에서는 중간 수준 피쳐 이상의 개념을 얻게 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da2a764",
   "metadata": {},
   "source": [
    "#### Spatial dimension\n",
    "\n",
    "32x32x3 이미지를 5x5x3의 필터를 갖고 연산을 수행하면 어떻게 28x28 actionvation map이 생기는지 알아보겠다. \n",
    "필터를 통해 슬라이딩을 기본적으로 한칸 씩 진행하는데 이때 움직이는 칸은 stride라고 한다. stride가 2라면 오른쪽으로 두칸씩 이동하는 형태 \n",
    "\n",
    "#### Output size 공식 \n",
    "$(N-F) / stride + 1 $ , N입력 차원, F 필터사이즈 \n",
    "\n",
    "#### zero-padding \n",
    "가장 자리의 필터연산을 수행하도록 하고 출력의 사이즈 의도대로 형성한다. 입력 사이즈를 유지할 수 있고 코너를 처리할 수 있다. zero-padding은 이미지의 가장자리에 0을 채워넣음으로써 왼쪽 상단의 자리에서도 필터 연산을 수행할 수 있게 된다. \n",
    "\n",
    "만약 여러개의 계층을 같이 쌓는다면 패딩을 적용안할 경우 얻게 되는 출력의 크기가 줄어들게 된다. 깊은 망을 갖게 되는 경우를 생각해보면 빠르게 활성지도의 크기가 작아질 것이다. 이는 정보의 일부를 잃는 것이고 훨씬 작은 숫자의 값만 사용하여 원본 이미지를 표현하는 것이다. \n",
    "\n",
    "\n",
    "**일반적으로 필터사이즈는 3x3, 5x5, stride는 보통 1,2, padding 은 설정에 따라 다르게, 필터의 갯수는 32,64,128,512등 의 2의 제곱수로 한다.**\n",
    "\n",
    "<img src=\"https://blog.kakaocdn.net/dn/dPfCWa/btqYurNPZAq/XRDWlwe22Lvp1ztfxsmah0/img.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://blog.kakaocdn.net/dn/bANxvt/btqYusFRrvj/6E2mZZSsdTTxSrYBDtEyMk/img.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "\n",
    "<img src=\"https://blog.kakaocdn.net/dn/1IVn7/btqYwgE6Kah/T4h9YakMovvkPvkX8kXGT1/img.png\" width=\"500\" height=\"300\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19e9317",
   "metadata": {},
   "source": [
    "### Poling Layer \n",
    "\n",
    "Poling layer는 representation들을 더 작고 관리하기 쉽게 해준다. representation을 작게 만드는 이유는 파라미더의 수가 줄게되고, 공간적인 불변성을 얻을 수 있기 때문이다. Poling layer가 하는 역할은 downsample을 하는 것이다. 예를 들면 224x224x64인 입력이 있다면 이를 112x112x64로 공간적으로 줄여주고. 중요한점은 깊이에는 영향을 주지 않는다는 점이다. \n",
    "\n",
    "Max Pooling이 일반적으로 쓰이는데, Pooling에도 필터 크기를 정할 수 있다. Conv layer가 했던 것처럼 슬라이딩을 하면서 연산을 수행하지만 내적을 하는 것이 아니라 필터안에 가장 큰 값중 하나를 고른다. Poling을 할때는 보통은 겹치지 않는것이 일반적이다. Max pooling 대신 average poolinge을 사용할 수 있지만 Max pooling은 그 지역이 어디든, 신호에 대해 얼마나 그 필터가 활성화 되었는지를 알려주기 때문에 사용한다. \n",
    "\n",
    "\n",
    "<img src=\"https://blog.kakaocdn.net/dn/cDDKma/btqYAtqTRGP/5SOmkYEr16wYQjRSInnIkk/img.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "<img src=\"https://blog.kakaocdn.net/dn/bnDtrY/btqYE8GkelY/BUnp2LCqpO9IJIO4UGSh30/img.png\" width=\"500\" height=\"300\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ba53c5",
   "metadata": {},
   "source": [
    "### LCN , Local Contrast Normalization \n",
    "\n",
    "국소 콘트라스트(대비) 정규화, 자연물 이미지 등 주변의 조명, 카메라의 노출 등 환경 변화에 따라 이미지 전체의 밝기,\n",
    "대비가 크게 변하는 경우 사용함, 이미지 밝기 정규화의 방법 이미지의 집합(훈련 데이터)에 대한 통계치를 이용하여 이미지의 명암을 전체적으로 조절\n",
    "이미지 한 장, 한 장에 대하여 개별적으로 조절,  고정된 가중치를 사용하므로 학습 가능한 파라미터는 없음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534fde07",
   "metadata": {},
   "source": [
    "## Batch Normalization \n",
    "\n",
    "#### Batch 란 전체 트레이닝 데이터 셋을 여러 작은 그룹을 나누었을 때, batch size는 하나의 소그룹에 속하는 데이터 수를 의미합니다. 전체 트레이닝 셋을 작게 나누는 이유는 트레이닝 데이터를 통째로 신경망에 넣으면 비효율적이 리소스 사용으로 학습 시간이 오래 걸리기 때문\n",
    "\n",
    "\n",
    "\n",
    "gradient descent에서는 gradient를 한번 업데이트 하기 위하여 모든 학습 데이터를 사용한다. 즉 학습 데이터를 전부 활용해 gradient를 구하고 그 모든 gradient를 평균해서 한번에 모델 업데이트를 한다. 이 방식으로 하게 되면 대용량의 데이터를 한번에 처리하지 못하기 떄문에 데이터를 batch 단위로 나눠서 학습을 하는 방법을 사용하는 것이 일반적이다\n",
    "\n",
    "문제점을 개선하기 위해 사용되는 방법이 stochastic gradient descent 입니다. SGD에서는 gradient를 한번 업데이트 하기 위하여 일부의 데이터만을 사용한다. 즉 batch size 만큼만 사용 \n",
    "\n",
    "* 학습데이터 전체를 한번 학습하는 것을 Epoch, Gradient을 구하는 단위를 Batch \n",
    "\n",
    "\n",
    "<img src=\"https://blog.kakaocdn.net/dn/dNIWC0/btqZPGBQpRH/W3YCM2pggUzkwP8JVEiMM0/img.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "* Makes deep networks much easier to train\n",
    "* improve gradient flow\n",
    "* Allows higher lr , faster convergence\n",
    "* Networks become more robust to initialization\n",
    "* Acts as regularization during traing\n",
    "* Zero overhead at test-time : can be fused with conv\n",
    "* Behaves differently during traing and testing : this is very common source of bugs\n",
    "\n",
    "Batch Normalization은 결국 condition num에 영향을 줘 solution space를 Smoothing ,립시츠 연속 함수 (Lipschitz continuity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fa0bdf",
   "metadata": {},
   "source": [
    "### Internal Covariant Shift \n",
    "\n",
    "\n",
    "Batch 단위로 학습을 하게 되면 발생하는 문제점이 있는데 Internal Covariant Shift 입니다.\n",
    "Internal Covariant Shift 은 학습 과정에서 계층 별로 입력의 데이터 분포가 달라지는 현상을 말한다.\n",
    "각 계층에서 입력으로 feature를 받게 되고 그 feature는 convolution이나 fully connected 연산을 거친 뒤 activation function을 적용하게 됩니다. 그러면 연산 전/후에 데이터 간 분포가 달라질 수가 있다. 이와 유사하게 Batch 단위로 학습을 하게 되면 Batch 단위간에 데이터 분포의 차이가 발생할 수 있다. Batch 간의 데이터가 상이하다고 말할 수 있는데 위에서 말한 Internal Covariant Shift 문제이다. 문제를 개선하기 위한 개념이 Batch Normalization 개념이 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a96b9b2",
   "metadata": {},
   "source": [
    "Batch Normalization은 학습 과정에서 각 배치 단위 별로 데이터가 다양한 분포를 가지더라도 각 배치별로 평균과 분산을 이용해 정규화하는 것을 의미\n",
    "배치 단위나 layer에 따라서 입력값의 분포가 모두 다르지만 정규화를 통하여 분포를 zero mean gussian 형태로 만든다.  \n",
    "\n",
    "평균을 0 , 표준 편차는 1   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fc0845",
   "metadata": {},
   "source": [
    "### 학습단계의 Batch Normalization 과 테스트시에 차이\n",
    "\n",
    "* 학습 단계 \n",
    "\n",
    "학습 단계의 Batch Normalization 을 구하기 위하여 사용된 평균과 분산을 구할 때에는 배치별로 계산되어야 의미가 있다. 각 배치들이 표준 정규 분포를 각각 따르게 되기 때문, 따라서 평균과 분산을 구할때에도 나눠주는 값이 B 이다.  \n",
    "\n",
    "학습 단계에서 모든 Feature에 정규화를 해주게 되면 정규화로 인하여 Feature가 동일한 Scale이 되어 learning rate 결정에 유리해진다.\n",
    "Feature의 Scale이 다르면 gradient descent를 하였을 때, gradient가 다르게 되고 같은 learning rate에 대하여 weight마다 반응하는 정도가 달라지게 된다.  \n",
    "\n",
    "gradient의 편차가 크면 gradient가 큰 weight에서는 gradient exploding이, 작으면 vanishing 문제가 발생하곤 한다. 하지만 정규화를 해주면 gradient descent에 따른 weight의 반응이 같아지기 때문에 학습에 유리해진다.여기서 사용된 값 중 gamma,β 의 역할을 확인하는 것이 필요하다.\n",
    "\n",
    "\n",
    "* ReLU 적용시 작동 원리   \n",
    "\n",
    "batch normalization을 적용하면 weight의 값이 평균이 0, 분산이 1인 상태로 분포가 되어지는데, 이 상태에서 ReLU가 activation으로 적용되면 전체 분포에서 음수에 해당하는 (1/2 비율) 부분이 0이 되어버립니다. 기껏 정규화를 했는데 의미가 없어져 버리게 됩니다.\n",
    "따라서 gamma,β 가 정규화 값에 곱해지고 더해져서 ReLU가 적용되더라도 기존의 음수 부분이 모두 0으로 되지 않도록 방지해 주고 있다. 물론 이 값은 학습을 통해서 효율적인 결과를 내기 위한 값으로 찾아갑니다.\n",
    "<img src=\"https://blog.kakaocdn.net/dn/sZB6f/btqZP2SeKhN/OkXooFJcdZALhv82kAGJV0/img.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "* 테스트 단계   \n",
    "\n",
    "추론 과정에서는  Batch Normalization 에 적용할 평균과 분산에 고정값을 사용한다. 학습 단계에서는 데이터가 배치 단위로 들어오기 때문에 배치의 평균, 분산을 구하는 것이 가능하지만, 테스트 단계에서는 배치 단위로 평균/분산을 구하기가 어려워 학습 단계에서 배치 단위의 평균/분산을 저장해 놓고 테스트 시에는 평균/분산을 사용한다.  \n",
    "\n",
    "이 때 사용할 고정된 평균과 분산은 학습 과정에서 이동 평균(running average) 또는 지수 평균(exponential average)을 통하여 계산한 값 즉, 학습 하였을 때의 최근  N개에 대한 평균 값을 고정값으로 사용 이동 평균을 하면  N 개 이전의 평균과 분산은 미반영 되지만 지수 평균을 사용하면 전체 데이터가 반영된다.그리고 이 때 사용되는  gamma,β 는 학습 과정에서 학습한 파라미터\n",
    "\n",
    "\n",
    "학습 과정과 추론 과정의 알고리즘이 다르므로 framework에서 사용할 때, 학습과정인지 추론과정인지에 따라 다르게 동작하도록 관리를 잘 해주어야 한다는 것 즉, 추론 과정에서는 framework에서 옵션을 지정하여 평균과 분산을 moving average/variance를 사용하도록 해야한다.\n",
    "\n",
    "<img src=\"https://blog.kakaocdn.net/dn/bgAvd2/btqZOr52mLg/c2C3jKc76JRwlq5aKcbZek/img.png\" width=\"500\" height=\"300\"/> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd7806c",
   "metadata": {},
   "source": [
    "### Instance Normlization \n",
    "\n",
    "주로 이미지 스타일 변환에 사용   \n",
    "\n",
    "Instance Normlization은 Contrast Normalization을 수행, 스타일 변화하고자 하는 이미지가 컨텐츠 이미지의 Contrast에 의존하지 않아야 한다.   \n",
    "\n",
    "입력 텐서의 수를 제외하고, Batch와 Instance 정규화는 같은 작업을 수행\n",
    "\n",
    "* Batch Normalization이 배치의 평균 및 표준 편차를 계산 (따라서 전체 계층 가우시안의 분포를 생성) \n",
    "\n",
    "* Instance Normalization은 각 mini-batch의 이미지 한장씩만 계산 하여 각각의 개별 이미지 분포를 사용\n",
    "\n",
    "-----\n",
    "\n",
    "### Layer Normalization \n",
    "\n",
    "동일한 층의 뉴런간 정규화\n",
    "\n",
    "* Mini-batch sample간 의존관계 없음\n",
    "\n",
    "* CNN의 경우 BatchNorm보다 잘 작동하지 않음(분류 문제)\n",
    "\n",
    "* Batch Norm이 배치 단위로 정규화를 수행했다면\n",
    "\n",
    "* Layer Norm은 Batch Norm의 mini-batch 사이즈를 뉴런 개수로 변경\n",
    "\n",
    "* 작은 mini-batch를 가진 RNN에서 성과를 보임\n",
    "\n",
    "* 입력 데이터의 scale에 대해 강건하다.\n",
    "\n",
    "* 가중치 행렬의 scale 및 shift에 대해 강건\n",
    "\n",
    "* 학습이 진행되며 자연적으로 updated scale가 작아짐\n",
    "\n",
    "\n",
    "### Group Normalization \n",
    "\n",
    "* Batch 사이즈가 극도로 작은 상황에서 batch normalization대신 사용하면 좋은 결과를 얻을 수 있음(Faster RCNN과 같은 네트워크)\n",
    "\n",
    "기존 Batch Norm은 특징맵의 평균과 분산값을 배치 단위로 계산해서 정규화 한다. 이때 계산되는 평균 값은 배치안의 데이터만 이용해서 계산되지만,  배치가 충분히 크다면 이 평균과 분산이 데이터셋 전체의 평균과 분산을 대표 할 수 있다는 가정을 가지고 있다.\n",
    "하지만 Batch Norm은 배치의 크기가 작으면 배치의 평균과 분산이 데이터셋 전체를 대표한다는 가정을 만족시키기는 어렵고, 구해지는 평균과 분산값도 매 iteration마다 달라진다.이러한 문제를 해결하기 위해 Group Norm을 개발하였음.각 채널을 N개의 그룹으로 나누어 정규화 한다. \n",
    "\n",
    "Instance Normalization과 유사함. 다만 여기서는 채널들을 그룹으로 묶어 평균과 표준편차를 구한다.마치 , Layer Normalization과 Instance Normalization의 중간정도라고 생각할 수 있다.만약, 모든 채널이 하나의 그룹으로 묶여있다면 Layer Normalization 이고 모든 채널이 각각의 그룹이 되어있다면 Instance Normalization이다.Group Normalization은 '이미지 인식 task'에서 batch size 32보다 작은 결과에 대해서는 Batch Normalization과 거의 근사하거나 나은 성능을 냈으며 큰 결과에 대해서는 좋지 못한 성능을 보여주었다.\n",
    "\n",
    "batch size가 크지 않은 경우 Group Normalization 사용하면 어느정도 잘 작동 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9c04cb",
   "metadata": {},
   "source": [
    "## CNN Architectures\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f401430",
   "metadata": {},
   "source": [
    "### LeNet \n",
    "\n",
    "LeNet은 산업에 성공적으로 적용된 최소의 ConvNet이다. LeNet은 이미지를 입력으로 받아서 stride =1 인 5x5 필터를 거치고 몇개의 Conv Layer와 pooling layer를 거치는 형식으로 구성되어 있다. 그리고 끝 단에 FC Layer가 붙는다. 숫자 인식에서 뛰어난 성능을 보인 모델이다. \n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FJ6XH3%2Fbtq1zsA1trC%2FDTMroINPsCjDhOwzukavu0%2Fimg.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac67589",
   "metadata": {},
   "source": [
    "### AlexNet \n",
    "\n",
    "2012년도 등장한 AlexNet은 최초의 Large scale CNN으로 Image Net이라는 이미지 분석 챌린지에서 분류 문제를 아주 효율적으로 해결했다. 기존의 모델들을 능가하는 성능을 보여주며 ConvNet 연구의 부흥을 일으켰다. \n",
    "\n",
    "AlexNet은 기본적으로 conv - pool- normalization 구조가 두번 반복된다. 그 뒤에 conv laryer가 조금 더 붙고 (conv, 3,4,5) 그 뒤에 pooling (Max POOL3) 가 있다. 마지막에는 FC layer가 몇개 붙는다. 구조만 봤을 때는 기존의 LeNet과 상당히 유사하고 레이어만 더 늘어나 보인다. AlexNet은 총 5개의 Conv Layer와 2개의 FC-Layer로 구성된다. \n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FQI2jJ%2Fbtq1xmhigD0%2FndO9JG4Yty5doDrAKylmh0%2Fimg.png\" width=\"600\" height=\"400\"/> \n",
    "\n",
    "\n",
    "\n",
    " 첫 레이어는 11x11 필터가 stride = 4로 96개가 존재한다. 첫 레이어의 출력값은 차원은 전체이미지 크기 - 필터크기/ stride +1 을 적용해서 55이다. 첫 레이어의 출력 사이즈는 55x55x96이다. (width, height는 각각 55, 필터가 96개 이므로 깊이는 96이다. 레이어의 전체 파라미터 갯수는 96x11x11x3 (11필터가 총 96개 , 필터크기 11x11x3입력의 깊이는 3이다. \n",
    "    \n",
    " 두번 째 레이어는 pooling layer로 stride = 2인 3x3 필터가 적용된다. 두번째 레이어의 출력 사이즈는 27x27x96이다. pooling layer에는 파라미터가 없다. 파라미터는 우리가 학습시키는 가중치 인데, Conv Layer에는 학습할 수 있는 가중치가 있지만 pooling의 경우에는 가중치가 없고 그저 특정 지역에서 큰 값을 뽑아내는 역할만 한다. 즉 학습시킬 파라미터가 없는 것 \n",
    "    \n",
    "  AlexNet은 총 5개의 ConvLayer가 존재하고 , 끝에 몇개의 FC-Layer가 있는데 4096개의 노드를 가진 레이어이다. 마지막 FC layer인 FC8은 softmax를 통과해 1000 ImangeNet클래스에 확률을 반환 \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aae3c2f",
   "metadata": {},
   "source": [
    "### ZFNet \n",
    "\n",
    "2013년 ImageNet Challange에서 우승한 모델, AlexNet의 하이퍼파라미터를 개선한 모델이다. AlexNet과 같은 레이어 수이고 기본적인 구조는 같지만 ,stride size, 필터 수 같은 하이퍼파라미터를 조절해서 AlexNet의 에러율을 개선 시켰다.\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F1EjaI%2Fbtq1uvy07uQ%2FqOIjrc66Ft9JCJvsRIn7kk%2Fimg.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8c893a",
   "metadata": {},
   "source": [
    "### VGGNet \n",
    "\n",
    "VGGNet는 기존의 모델들보다 네트워크가 훨씬 더 깊어졌고, 더 작은 필터를 사용한것이다. AlexNet에서는 8개의 레이어 였지만 ,VGGNet는 16애서 19개의 레이어를 가진다. 항상 3x3필터만 사용하는데 이는 이웃픽셀을 포함할 수 있는 가장 작은 필터이다. 작은 필터를 유지해주고, 주기적으로 pooling을 수행하면서 전체 네트워크를 구성 한다. \n",
    "\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FwTf2z%2Fbtq1xlCRQIK%2FIsQ31fK3yPkGfmtyDKaTI1%2Fimg.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "\n",
    " VGGNet이 작은 필터를 사용하는 이유를 살펴 보겠다. 우선의 필터의 크기가 작으면 레이어의 파라미터의 수가 적어짐으로 큰 필터링에 비해 레이터를 조금 더 많이 쌓을 수 있다. 즉 작은 필터를 사용하면 Depth를 더 키울 수 있다. 3x3필터는 여러개 쌓은 것은 결국 7x7를 사용하는 것과 실질적으로 동일한 Receptive Field를 가진다. Receptive Field는 필터가 한번에 볼 수 있는 입력의 Spatial area이다. (출력 레이어의 뉴런 하나에 영향을 미치는 입력 뉴런들의 공간크기).\n",
    " \n",
    "\n",
    "Stride가 1인 3x3 필터를 세개를 쌓게 되면 첫번 째 레이어의 Receptive Field는 3x3이다. 두번 째 레이어의 경우는 각 뉴런이 첫 번째 레이어의 출력의 3x3만큼을 보고 3x3중에 각 사이드는 한 픽셀씩 더 볼 수 있다. 실제로는 두번 레이어의 경우 5x5의 Receptive Field를 가지게 된다. \n",
    "\n",
    "세번 째 레이어의 경우는 두번 째 레이어 3x3을 본다. 결국 7x7을 보게 되고 실질적인 Receptive Field는 7x7로, 3x3필터 세개를 쌓는 것이 하나의 7x7필터를 사용하는 것과 동일하다고 볼 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa6f190",
   "metadata": {},
   "source": [
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F8XZUA%2Fbtq1xnm54cw%2FxAIwLnEksq2dyZtbc862Uk%2Fimg.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "VGGNet은 AlexNet과 비슷한 패턴이 반복된다. Conv Layer와 Pooling Layer가 반복적으로 진행되는 패턴이다. \n",
    "VGG16와 VGG19는 아주 유사하고 ,VGG가 조금 더 깊다. 네트워크를 살펴보면 AlexNet에서 처럼 모델 성능을 위해서 앙상블 기법을 사용했다. VGG의 마지막 FC-Layer인 FC7은 이미지넷 1000 class의 바로 직전에 위치한 레이어인데, 4096사이즈로 아주 좋은 feature represetation을 가지고 있는 것으로 보인다. 다른 데이터 에서도 특징 추출이 잘 되며 다른 task에서도 일반화 능력이 뛰어난 것으로 알려저 있다. \n",
    "\n",
    "-----\n",
    "\n",
    "3x3 한계는 Receptive Field이다. 현재의 데이터들은 input 이미지의 사이즈가 굉장히 커지고 있는데 3x3을 통해 Receptive Field 확보가 어려워짐 , 현대에는 (RepLK 논문)  31x31의 큰 필터를 섞어 Receptive Field를 확보해주면 어떨까라는 연구가 이루어지고 있다. but 파라미터 수가 늘어난나는 것이 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2afaa7",
   "metadata": {},
   "source": [
    "### GoogLeNet \n",
    "\n",
    "GoogLeNet은 엄청 깊은 레이어로, 22개의 레이러를 가지고 있다. GoogLeNet 중요한 점은 효율적인 계산에 관한 그들의 특별한 관점이 있다는 것과 높은 계산량을 효율적으로 수행하도록 네트워크를 디자인 했다는 점이다. GoogLeNet은 Inception module을 여러개 쌓아서 만들었다. FC-Layer가 없는데. 이는 파라미터를 줄이기 위해서 이다. \n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FE8fTk%2Fbtq1xlQmjOs%2FU8Rygfh0KNhzJmA7VFGpn1%2Fimg.png\" width=\"600\" height=\"400\"/> \n",
    "\n",
    "\n",
    "Inception Module 내부에는 동일한 입력을 받는 서로 다른 다양한 필터들이 병렬로 존재한다. 이전 레이어의 입력을 받아서 다양한 Conv연산을 수행한다. \n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fm6m8z%2Fbtq1z4GROVo%2Fy5XfNb16hCyxv8zJI7QBTK%2Fimg.png\" width=\"700\" height=\"300\"/> \n",
    "\n",
    " 1x1/3x3/5x5 conv/pooling(3x3)가 각각의 레이어로 동일한 입력을 받는다. 각 레이어에서 연산 후에 각각의 출력 값들이 나오는데, 출력들을 모두 깊이 방향으로 합친다. 합치게 되면 하나의 텐서로 출력이 결정되고, 하나의 출력을 다음 레이어로 전달하는 형태로 진행된다.  \n",
    " \n",
    "Inception 모듈은 계산비용에 문제가 존재한다. 계산을 통해 모든 출력 값들을 합친 사이즈를 계산해보면 spartial dimention은 변하지 않지만 깊이가 엄청 커지게 된다. 예를 들어 입력이 28x28x256이면 출력은 28x28x672가 된다, 28x28x(128+192+96+256). 연산량이 커지게 되고 pooling layer의 입력이 깊이를 그대로 유지하기 때문에 문제를 악화시킨다. \n",
    "\n",
    "문제를 해결하기 위해 GoogLeNet이 사용한 방법은 bottleneck 계층을 사용했다. 합성곱 연산전에 피쳐들을 낮은 차원으로 사영 \n",
    "입력을 받아서 각 공간 위치에서 내적으로 하고 공간차원을 유지하며 깊이를 줄인다. 입력의 깊이를 낮은 차원으로 사영해서 깊이를 줄인다. 입력 피쳐 map의 선형 조합과 같은 것이다. \n",
    "\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F2eYs9%2Fbtq1vizCZr5%2Fobg7VL00pvKztJDEMdLl0K%2Fimg.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FGLdjR%2Fbtq1AFfNiM7%2F6XykOEG1lGspcQdVIae0h0%2Fimg.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "우리는 여전히 28 x 28 x 256의 같은 입력을 갖고 있다. 그러나 1 x 1 콘브들이 깊이 차원을 줄일 것이다. 3 x 3 콘브 전에, 1 x 1 콘브 64개의 필터를 넣으면, 그것으로부터의 출력은 28 x 28 x 64가 될 것이다.  3 x 3 콘브로 가는 대신, 나중에 28 x 28 x 256이 오는 것이 아니라, 우리는 단지 28 x 28 x 64 블록 (block)이 오는 것이다. 그래서 이건 더 작은 입력을 줄여서 이 콘브 계층으로 가게 하는 것이다. 5 x 5 콘브에 대해서도 같은 것이고, 풀링 계층에 대해서는, 풀링이 나온 다음, 이 후에 깊이를 줄일 것이다. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FVN94E%2Fbtq1uve0j1w%2F0z4O5tWE0YkSwLGcmM0DK1%2Fimg.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbUEYxt%2Fbtq1s3QNSAn%2FblKbfChRaaYq0S5R7Vyb1k%2Fimg.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc7ZECO%2Fbtq1yEvmWFA%2Fzmo8dbGaxKcnDrSQar6moK%2Fimg.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbMWMlV%2Fbtq1yXVNrfF%2F6YMoRjL20KR5LqaUdKGEeK%2Fimg.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbyufVA%2Fbtq1z4Uq2pQ%2FY7xqAXCwvl7ENelq4x5l3K%2Fimg.png\" width=\"500\" height=\"300\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e8b69d",
   "metadata": {},
   "source": [
    "### ResNet \n",
    "\n",
    "CNN을 연구하면서 기존 모델들은 Layer을 깊게 쌓을 수록 성능이 더 좋아질것이라고 예상했지만, 실제로는 20층 이상부터 성능이 낮아지는 현상인 Degradation 문제가 발생했습니다. ResNet은 Residual Learning이라는 개념을 통해 모델의 층이 깊어져도 학습이 잘 되도록 구현한 모델이다. \n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcmzwwN%2Fbtq1yGf6gpb%2Faz5iSDYzrnm3rCW5O48Fr0%2Fimg.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcIpMtf%2Fbtq1C1pzmjh%2FvztxQG1BaQ5PM8tN5kQy50%2Fimg.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FPfdny%2Fbtq1uvl9NVg%2Fs8jZGKJYTNBBFPku4sjO01%2Fimg.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857a9abd",
   "metadata": {},
   "source": [
    "### Residual Block 사용 \n",
    "\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcFopOn%2Fbtq1C2vfp5X%2FYfIt9rRUbPbetZ7tk6v2Uk%2Fimg.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "\n",
    "H(x)를 기존의 네트워크라고 할 때, H(x)를 복잡한 함수에 근사시키는 것 보다 F(x) := H(x) - x일 때, H(x) = F(x) + x이고, F(x) + x를 근사시키는 것이 더 쉬울 것이라는 아이디어에서 출발. 원래 Output에서 자기자신을 빼는 것이 F(x)의 정의이므로, 'Residual learning'이라는 이름을 갖게 된다. 또한, x가 F(x)를 통과하고 나서 다시 x를 더해주기 때문에 이를 Skip Connection이라고 부른다. \n",
    "\n",
    "x : 입력값\n",
    "F(x) : CNN Layer -> ReLU -> CNN Layer 을 통과한 출력값\n",
    "H(x) : CNN Layer -> ReLU -> CNN Layer -> ReLU 를 통과한 출력값\n",
    "기존 신경망은 H(x)가 정답값 y에 정확히 매핑이 되는 함수를 찾는것을 목적으로 한다. 즉 신경망은 학습을 하면서 H(x) -y 의 값을 최소화시키면서 결국 H(x) = y가 되는 함수를 찾는다. \n",
    "\n",
    "기존 신경망이 H(x) - x = 0을 만들려 했다면 ResNet은 H(x) - x = F(x) 로 두어 F(x)를 최소화 시키려고 한다. 즉 F(x) = 0 이라는 목표를 두고 학습을 진행한다. 이렇게 학습을 진행하면 F(x) = 0이라는 목표값이 주어지기 때문에 학습이 더 쉬워ㄴ. 결국 H(x) = F(x) + x 가 되는데 이때 입력값인 x를 사용하기 위해 쓰는 것이 Skip Connection이다. 즉 Skip Connection은 입력 값이 일정 층들을 건너뛰어 출력에 더할 수 있게 하는 역할을 한다.\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FrccGd%2Fbtq1yEijMJR%2FGvdJkHtMTZcieNPwsbqLs1%2Fimg.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "\n",
    "\n",
    "참조 : https://wikidocs.net/137252\n",
    "\n",
    "\n",
    "\n",
    "매우 깊은 망에 대해서 즉 ,즉, 50계층 깊이 이상인 것에 대해서는 효율성을 개선하기 위해 구글넷이 했던 것과 비슷한 병목 (bottleneck) 계층을 사용\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbmx5xP%2Fbtq1C05g1KV%2F8uHDDt2l6g6e481OkiJcu0%2Fimg.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbMi0AS%2Fbtq1yX9Mi17%2FwTxbjaOJ5Wyb3GRlgkxaik%2Fimg.png\" width=\"500\" height=\"300\"/> \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
