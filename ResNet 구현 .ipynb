{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e807e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ffba3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공통 Arguments\n",
    "## pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "## progress (bool): If True, displays a progress bar of the download to stderr\n",
    "\n",
    "# 기본 ResNet 34층\n",
    "def resnet34(pretrained=False, progress=True, **kwargs):\n",
    "    return _resnet('resnet34', BasicBlock, [3, 4, 6, 3], pretrained, progress, **kwargs)\n",
    "\n",
    "# 기본 ResNet 50층\n",
    "def resnet50(pretrained=False, progress=True, **kwargs):\n",
    "    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress, **kwargs)\n",
    "\n",
    "# Wide ResNet\n",
    "def wide_resnet50_2(pretrained=False, progress=True, **kwargs):\n",
    "    kwargs['width_per_group'] = 64 * 2\n",
    "    return _resnet('wide_resnet50_2', Bottleneck, [3, 4, 6, 3], pretrained, progress, **kwargs)\n",
    "\n",
    "# ResNext\n",
    "def resnext50_32x4d(pretrained=False, progress=True, **kwargs):\n",
    "    kwargs['groups'] = 32 # input channel을 32개의 그룹으로 분할 (cardinality)\n",
    "    kwargs['width_per_group'] = 4 # 각 그룹당 4(=128/32)개의 채널으로 구성.\n",
    "    # 각 그룹당 channel 4의 output feautre map 생성, concatenate해서 128개로 다시 생성.\n",
    "    \n",
    "    return _resnet('resnext50_32x4d', Bottleneck, [3, 4, 6, 3], pretrained, progress, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c26743d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
    "    r\"\"\"\n",
    "    - pretrained: pretrained된 모델 가중치를 불러오기 (saved by caffe)\n",
    "    - arch: ResNet모델 이름\n",
    "    - block: 어떤 block 형태 사용할지 (\"Basic or Bottleneck\")\n",
    "    - layers: 해당 block이 몇번 사용되는지를 list형태로 넘겨주는 부분\n",
    "    \"\"\"\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch], progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0214672",
   "metadata": {},
   "source": [
    "### Convloution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80cbdee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    r\"\"\"\n",
    "    3x3 convolution with padding\n",
    "    - in_planes: in_channels\n",
    "    - out_channels: out_channels\n",
    "    - bias=False: BatchNorm에 bias가 포함되어 있으므로, conv2d는 bias=False로 설정.\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a71ab9",
   "metadata": {},
   "source": [
    "### Basic Block \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42db3051",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        r\"\"\"\n",
    "         - inplanes: input channel size\n",
    "         - planes: output channel size\n",
    "         - groups, base_width: ResNext나 Wide ResNet의 경우 사용\n",
    "        \"\"\"\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "            \n",
    "        # Basic Block의 구조\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)  # conv1에서 downsample\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        # short connection\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "            \n",
    "        # identity mapping시 identity mapping후 ReLU를 적용합니다.\n",
    "        # 그 이유는, ReLU를 통과하면 양의 값만 남기 때문에 Residual의 의미가 제대로 유지되지 않기 때문입니다.\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
