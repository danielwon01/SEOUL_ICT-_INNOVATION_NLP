{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b12142dc",
   "metadata": {},
   "source": [
    "## CNN \n",
    "\n",
    "영상인식 처리 분야에 있어서 가장 기본이 되는 모델 \n",
    "눈과 뇌에서 처리되는 신경과학적 시각처리 방식에서 고안한 모델 \n",
    "\n",
    "신경망 동작을 처리하기 위하여 합성곱 연산을 이용 \n",
    "CNN 모델에서는 합성곱 연산을 기반으로 각 픽셀이 서로 얼마나 일치하는지 계산하여 그 계산 결과를 활용`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc54f4e",
   "metadata": {},
   "source": [
    "### FC,Fully Conneted Layer \n",
    "\n",
    "<img src=\"https://blog.kakaocdn.net/dn/MFv6C/btqXFgyDRGq/lG2ivJWQwR1qM7gVAtZG8K/img.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "FC는 벡터들의 연산을 진행, 32x32x3의 이미지를 flatten하게 펴서 3072차원의 벡터로 만든다. 가중치 W(10x3072)를 벡터와 곱하고 activation을 이 layer의 출력값으로 얻는다. 일반적으로 기존의 신경망에서 각 층별 연결에 사용되는 방식. 전결합층 이다. 모든 노드를 연결하므로 수많은 연산이 일어남, CNN 의 특징은 모든 노드를 결합하지 않음으로써 연산량을 줄여 효율성을 높이는 방식 \n",
    "\n",
    "FC 특징 \n",
    "모든 노드를 연결하므로 1차원배열로 표시됨,이미지의 공간정보가 사라짐, 최종 결과값은 분류 결과 도출, 결국 마지막에 도출된 분류결과 Label을 선택하여야 , 최종 결과를 분류하기 위한 기반 정보는 모두 가지고 있어야 분류를 위한 SoftMax 함수를 사용할 수 있음, 필수는 아니며 Convolution Layer 의 결과를 그대로 사용할 수도 있음\n",
    "\n",
    "**FC와 Convolution layer의 차이점은 Convonlution는 기존의 구조를 보존시키다는 것이다. 32x32x3의 이미지지를 flatten시키는 것이 아니라 기존의 이미지 구조를 그대로 유지한다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b898f942",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.kakaocdn.net/dn/XS44I/btqYE7GEYMc/BzE6v6k1kohceoewC3iRDK/img.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "합성곱의 가중치는 사진에서 보이는 봐와 같이 파란색의 작은 필터가 가중치가 된다. 필터를 이용해 이미지를 슬라이딩 하면서 공간적으로 내적을 수행하게 된다. \n",
    "필터는 이미지의 깊이 만큼 확장된다. 필터의 높이와 넓이는 기존 이미지를 넘지 않는 선에서 정해질 수 있지만 깊이는 기존 이미지와 동일하게 정해져야 한다. \n",
    "\n",
    "필터가 슬라이딩할 때, Convolution은 이미지의 좌상단부터 시작한다. 필터의 모든 요소를 가지고 내적을 수행하게 되면 하나의 값을 얻게 된다. 합성곱 연산을 수행하는 값들을 다시 output activation map에 해당하는 위치에 저장한다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f7418c",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.kakaocdn.net/dn/llPou/btqYB5P4ohc/q0lYvk9csFdBABeYame6XK/img.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "합성곱 계층을 다룰 때는 여러 필터로 작업, 필터 마다 다른 특징을 추출하고 싶기 때문이다. 한 layer에서 원하는 만큼 여러개의 필터를 사용할 수 있다. \n",
    "CNN은 Convolution layer의 연속된 형태가 된다. 각각을 쌓아 올리게 되면 Linear layer로 된 Neeural Network가 되고 그 사이에 ReLu 같은 활성화 함수를 넣는다. 각 layer의 출력은 다음 layer의 입력이 되고 각 layer는 여러개의 필터를 가지고 각 필터마다 각각의 출력 map을 만든다. 결국 각 필터들이 계층적으로 학습을 하게 된다.\n",
    "\n",
    "<img src=\"https://blog.kakaocdn.net/dn/vxxfq/btqYvdIqP6X/LIjuKWivjZyknWkmlts8AK/img.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec518657",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.kakaocdn.net/dn/btgMpf/btqYurfRzIh/neKbjm9LeqQ38lQ9gQ9k41/img.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "초기 레이어의 필터들은 낮은 수준의 피저들을 표현, 중간 수준에선 더 복잡한 종류의 피쳐들을 얻게 된다. 그 뒤 더 높은 수준의 피쳐에서는 중간 수준 피쳐 이상의 개념을 얻게 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da2a764",
   "metadata": {},
   "source": [
    "#### Spatial dimension\n",
    "\n",
    "32x32x3 이미지를 5x5x3의 필터를 갖고 연산을 수행하면 어떻게 28x28 actionvation map이 생기는지 알아보겠다. \n",
    "필터를 통해 슬라이딩을 기본적으로 한칸 씩 진행하는데 이때 움직이는 칸은 stride라고 한다. stride가 2라면 오른쪽으로 두칸씩 이동하는 형태 \n",
    "\n",
    "#### Output size 공식 \n",
    "$(N-F) / stride + 1 $ , N입력 차원, F 필터사이즈 \n",
    "\n",
    "#### zero-padding \n",
    "가장 자리의 필터연산을 수행하도록 하고 출력의 사이즈 의도대로 형성한다. 입력 사이즈를 유지할 수 있고 코너를 처리할 수 있다. zero-padding은 이미지의 가장자리에 0을 채워넣음으로써 왼쪽 상단의 자리에서도 필터 연산을 수행할 수 있게 된다. \n",
    "\n",
    "만약 여러개의 계층을 같이 쌓는다면 패딩을 적용안할 경우 얻게 되는 출력의 크기가 줄어들게 된다. 깊은 망을 갖게 되는 경우를 생각해보면 빠르게 활성지도의 크기가 작아질 것이다. 이는 정보의 일부를 잃는 것이고 훨씬 작은 숫자의 값만 사용하여 원본 이미지를 표현하는 것이다. \n",
    "\n",
    "\n",
    "**일반적으로 필터사이즈는 3x3, 5x5, stride는 보통 1,2, padding 은 설정에 따라 다르게, 필터의 갯수는 32,64,128,512등 의 2의 제곱수로 한다.**\n",
    "\n",
    "<img src=\"https://blog.kakaocdn.net/dn/dPfCWa/btqYurNPZAq/XRDWlwe22Lvp1ztfxsmah0/img.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://blog.kakaocdn.net/dn/bANxvt/btqYusFRrvj/6E2mZZSsdTTxSrYBDtEyMk/img.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "\n",
    "<img src=\"https://blog.kakaocdn.net/dn/1IVn7/btqYwgE6Kah/T4h9YakMovvkPvkX8kXGT1/img.png\" width=\"500\" height=\"300\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19e9317",
   "metadata": {},
   "source": [
    "### Poling Layer \n",
    "\n",
    "Poling layer는 representation들을 더 작고 관리하기 쉽게 해준다. representation을 작게 만드는 이유는 파라미더의 수가 줄게되고, 공간적인 불변성을 얻을 수 있기 때문이다. Poling layer가 하는 역할은 downsample을 하는 것이다. 예를 들면 224x224x64인 입력이 있다면 이를 112x112x64로 공간적으로 줄여준. 중요한점은 깊이에는 영향을 주지 않는다는 점이다. \n",
    "\n",
    "Max Pooling이 일반적으로 쓰이는데, Pooling에도 필터 크기를 정할 수 있다. Conv layer가 했던 것처럼 슬라이딩을 하면서 연산을 수행하지만 내적을 하는 것이 아니라 필터안에 가장 큰 값중 하나를 고른다. Poling을 할때는 보통은 겹치지 않는것이 일반적이다. Max pooling 대신 average poolinge을 사용할 수 있지만 Max pooling은 그 지역이 어디든, 신호에 대해 얼마나 그 필터가 활성화 되었는지를 알려주기 때문에 사용한다. \n",
    "\n",
    "\n",
    "<img src=\"https://blog.kakaocdn.net/dn/cDDKma/btqYAtqTRGP/5SOmkYEr16wYQjRSInnIkk/img.png\" width=\"500\" height=\"300\"/> \n",
    "\n",
    "<img src=\"https://blog.kakaocdn.net/dn/bnDtrY/btqYE8GkelY/BUnp2LCqpO9IJIO4UGSh30/img.png\" width=\"500\" height=\"300\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ba53c5",
   "metadata": {},
   "source": [
    "### LCN , Local Contrast Normalization \n",
    "\n",
    "국소 콘트라스트(대비) 정규화, 자연물 이미지 등 주변의 조명, 카메라의 노출 등 환경 변화에 따라 이미지 전체의 밝기,\n",
    "대비가 크게 변하는 경우 사용함, 이미지 밝기 정규화의 방법 이미지의 집합(훈련 데이터)에 대한 통계치를 이용하여 이미지의 명암을 전체적으로 조절\n",
    "이미지 한 장, 한 장에 대하여 개별적으로 조절,  고정된 가중치를 사용하므로 학습 가능한 파라미터는 없음\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
