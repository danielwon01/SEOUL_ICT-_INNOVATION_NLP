{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fed49cd",
   "metadata": {},
   "source": [
    "# **CNN을 이용한 자연어 처리**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907c58fa",
   "metadata": {},
   "source": [
    "---\n",
    "- 참고도서\n",
    "  - 파이토치로 배우는 자연어처리(델립라오, 브라이언 맥머핸 지음 / 박해선 옮김 | 한빛미디어)\n",
    "  - 텐서플로 2와 머신러닝으로 시작하는 자연어 처리 (전창욱, 최태균, 조종현, 신성진 지음 | 위키북스)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24601160",
   "metadata": {},
   "source": [
    "## PyTorch로 CNN 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6838df9a",
   "metadata": {},
   "source": [
    "#### 데이터 만들기\n",
    "- 특성 벡터를 만들기 위하여 실제 데이터와 크기가 같은 3차원의 인공 데이터 텐서 생성\n",
    "- 파이토치의 Conv1d 클래스의 객체를 생성한 3차원 데이터 텐서에 적용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "870fd19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d644e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25849475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7576, -0.0045, -1.9715, -0.5319, -0.2123,  0.2447, -0.6172],\n",
       "         [-0.1312, -0.2751, -1.7393,  0.8883, -1.6621, -1.0706, -0.1837],\n",
       "         [ 0.0487,  0.1725,  1.5112, -0.2176, -0.5876,  0.3950,  1.0962],\n",
       "         [ 0.9788, -0.3444,  2.0185, -1.0012,  1.1342,  1.4656, -0.0960],\n",
       "         [ 0.3063,  0.1864, -0.8776,  0.8486,  0.7107,  0.8068, -2.1056],\n",
       "         [ 0.6060, -0.9974, -0.8422,  1.5139,  0.2831,  1.2560,  0.5766],\n",
       "         [-1.7194, -0.0405, -0.1482, -0.9285, -1.3134,  0.7190, -1.0809],\n",
       "         [ 1.2016,  0.3256,  0.4886,  0.5783, -0.7330, -2.3401,  1.5176],\n",
       "         [-0.8773,  0.6862, -0.7837,  0.4169,  1.3590, -1.8919, -0.4479],\n",
       "         [ 0.1601,  0.2753,  0.8682, -1.0069,  1.5728, -0.5722,  0.3867]],\n",
       "\n",
       "        [[ 0.0409,  0.2428, -0.4886, -2.4076, -0.9827, -0.2258,  1.9579],\n",
       "         [-0.8736,  0.7104,  0.8309, -1.5838, -0.0865, -2.4078, -1.1908],\n",
       "         [-1.3877,  1.0680, -1.7280,  1.4052,  1.9184,  0.2795, -2.1694],\n",
       "         [ 0.0575, -0.7633, -0.2839, -1.2654,  0.5317,  1.0783,  1.1932],\n",
       "         [-1.0891,  0.4873,  1.5256, -1.3725, -1.3911,  1.8619,  0.6245],\n",
       "         [ 1.1539,  0.5287, -0.5014, -1.9086,  0.7579, -1.0161, -1.6595],\n",
       "         [ 1.2695,  0.7500, -0.0184,  0.6028,  0.3462,  1.2199, -0.1521],\n",
       "         [-0.3624,  0.0086,  0.0451, -0.1826,  0.4038,  0.7779, -1.5041],\n",
       "         [ 0.5731, -0.3121,  3.0177, -1.5488, -1.8821, -0.2241,  1.1431],\n",
       "         [-0.0695, -0.9048,  0.7388, -3.1657,  0.6418,  0.0381, -1.1926]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2 \n",
    "one_hot_size = 10\n",
    "sequence_width = 7\n",
    "\n",
    "data = torch.randn(batch_size, one_hot_size, sequence_width)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4464e0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 7])\n",
      "torch.Size([2, 16, 5])\n"
     ]
    }
   ],
   "source": [
    "#  1D convolution 연산은 가로로만 이동하면서 output을 계산\n",
    "conv1 = nn.Conv1d(in_channels=one_hot_size, out_channels=16, kernel_size=3)\n",
    "intermediate1 = conv1(data)\n",
    "\n",
    "print(data.size())\n",
    "print(intermediate1.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47d2d0f",
   "metadata": {},
   "source": [
    "Parameters\n",
    "\n",
    "* in_channels: input의 feature dimension\n",
    "* out_channels: output으로 내고싶은 dimension\n",
    "* kernel_size: time step을 얼마만큼 볼 것인가(=frame size = filter size)\n",
    "* stride: kernel을 얼마만큼씩 이동하면서 적용할 것인가 (Default: 1) -> 아래 추가 설명\n",
    "* dilation: kernel 내부에서 얼마만큼 띄어서 kernel을 적용할 것인가 (Default: 1) -> 아래 추가 설명\n",
    "* padding: 한 쪽 방향으로 얼마만큼 padding할 것인가 (그 만큼 양방향으로 적용) (Default: 0)\n",
    "* groups: kernel의 height를 조절 (Default: 1) -> 아래 추가 설명\n",
    "* bias: bias term을 둘 것인가 안둘 것인가 (Default: True)\n",
    "* padding_mode: 'zeros', 'reflect', 'reflect', 'replicate', 'circular' (Default: 'zeros')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881d9843",
   "metadata": {},
   "source": [
    "- 데이터에 합성곱 반복 적용\n",
    "  - 합성곱을 추가하여 출력 텐서의 크기를 줄이는 작업을 반복 적용\n",
    "  - 코드에서는 3번의 합성곱 후에 출력의 마지막 차원이 size=1이 되도록 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c19e7de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32, 3])\n",
      "torch.Size([2, 64, 1])\n"
     ]
    }
   ],
   "source": [
    "conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3)\n",
    "conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "\n",
    "intermediate2 = conv2(intermediate1)\n",
    "intermediate3 = conv3(intermediate2)\n",
    "\n",
    "print(intermediate2.size())\n",
    "print(intermediate3.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a1c4447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64])\n"
     ]
    }
   ],
   "source": [
    "y_output = intermediate3.squeeze()\n",
    "print(y_output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acf2a6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate2.mean(dim=0).mean(dim=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce2286d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 80])\n",
      "torch.Size([2, 16])\n"
     ]
    }
   ],
   "source": [
    "# 특성 벡터를 줄이는 방법 1\n",
    "print(intermediate1.view(batch_size, -1).size())\n",
    "\n",
    "# 특성 벡터를 줄이는 방법 2\n",
    "print(torch.mean(intermediate1, dim=2).size())\n",
    "# print(torch.max(intermediate1, dim=2).size())\n",
    "# print(torch.sum(intermediate1, dim=2).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7af55f",
   "metadata": {},
   "source": [
    "- 배치 정규화와 Conv1D 층 사용하기\n",
    "  - 전체 모델을 다시 만들지 않고 배치 정규화를 사용하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d631eaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16, 5])\n",
      "torch.Size([2, 32, 3])\n",
      "torch.Size([2, 64, 1])\n"
     ]
    }
   ],
   "source": [
    "conv1 = nn.Conv1d(in_channels=one_hot_size, out_channels=16, kernel_size=3)\n",
    "conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3)\n",
    "conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "\n",
    "conv1_bn = nn.BatchNorm1d(num_features=16)\n",
    "conv2_bn = nn.BatchNorm1d(num_features=32)\n",
    "    \n",
    "intermediate1 = conv1_bn(F.relu(conv1(data)))\n",
    "intermediate2 = conv2_bn(F.relu(conv2(intermediate1)))\n",
    "intermediate3 = conv3(intermediate2)\n",
    "\n",
    "print(intermediate1.size())\n",
    "print(intermediate2.size())\n",
    "print(intermediate3.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c33742d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.9868e-08,  9.9341e-09,  0.0000e+00,  0.0000e+00, -5.9605e-08,\n",
       "         0.0000e+00, -1.9868e-08,  0.0000e+00,  1.9868e-08,  0.0000e+00,\n",
       "         3.9736e-08, -3.9736e-08,  1.0928e-07, -1.9868e-08, -7.9473e-08,\n",
       "         7.9473e-08,  0.0000e+00, -1.9868e-08, -4.9671e-08,  0.0000e+00,\n",
       "        -1.9868e-08,  3.9736e-08,  0.0000e+00, -5.9605e-08, -9.9341e-09,\n",
       "        -1.9868e-08,  0.0000e+00, -1.9868e-08,  1.9868e-08,  0.0000e+00,\n",
       "        -1.9868e-08,  0.0000e+00], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 노트: \n",
    "# 배치 정규화는 배치와 시퀀스 차원에 대해 통곗값을 계산합니다. \n",
    "# 다른 말로하면 BatchNorm1d에 입력되는 텐서의 크기는 (B, C, L)입니다(B는 배치, C는 채널, L은 길이).\n",
    "# 각 (B, L) 슬라이스마다 원점에 평균을 맞춥니다. \n",
    "# 이는 공변량 변화(covariate shift)를 줄입니다.\n",
    "\n",
    "intermediate2.mean(dim=(0, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65060a3f",
   "metadata": {},
   "source": [
    "- 여러 하이퍼파라미터 설정으로 합성곱 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb6ee49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(x):\n",
    "    print(\"타입: {}\".format(x.type()))\n",
    "    print(\"크기: {}\".format(x.shape))\n",
    "    print(\"값: \\n{}\".format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59452e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([1, 2, 3, 3])\n",
      "값: \n",
      "tensor([[[[ 0.4789, -0.4305, -1.4366],\n",
      "          [-1.1571, -0.2315, -0.1990],\n",
      "          [-1.1098,  0.5366, -0.9539]],\n",
      "\n",
      "         [[-0.8122, -0.2839,  0.0485],\n",
      "          [-0.6061, -0.0737,  0.3725],\n",
      "          [ 1.1321,  0.4685, -0.0777]]]])\n",
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([1, 2, 2, 2])\n",
      "값: \n",
      "Parameter containing:\n",
      "tensor([[[[-0.0796, -0.0980],\n",
      "          [-0.2961, -0.1258]],\n",
      "\n",
      "         [[-0.0006, -0.2372],\n",
      "          [ 0.0707,  0.1871]]]], requires_grad=True)\n",
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([1, 1, 2, 2])\n",
      "값: \n",
      "tensor([[[[0.6016, 0.5363],\n",
      "          [0.7760, 0.1439]]]], grad_fn=<ThnnConv2DBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 2, 3, 3)\n",
    "describe(x)\n",
    "\n",
    "conv1 = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=2)\n",
    "describe(conv1.weight)\n",
    "describe(conv1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c65e2bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([1, 1, 3, 3])\n",
      "값: \n",
      "tensor([[[[ 2.4933, -0.7148, -1.3619],\n",
      "          [-0.9292,  0.7830,  1.6472],\n",
      "          [-1.8585, -0.2598, -1.3071]]]])\n",
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([2, 1, 2, 2])\n",
      "값: \n",
      "Parameter containing:\n",
      "tensor([[[[ 0.3624, -0.1627],\n",
      "          [-0.0152,  0.2332]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2244,  0.0540],\n",
      "          [ 0.2330,  0.2627]]]], requires_grad=True)\n",
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([1, 2, 2, 2])\n",
      "값: \n",
      "tensor([[[[ 0.9779,  0.0960],\n",
      "          [-0.7352, -0.5238]],\n",
      "\n",
      "         [[ 0.2211,  0.0922],\n",
      "          [-0.9564, -0.4283]]]], grad_fn=<ThnnConv2DBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 1, 3, 3)\n",
    "describe(x)\n",
    "\n",
    "conv1 = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=2)\n",
    "describe(conv1.weight)\n",
    "describe(conv1(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ced2d98",
   "metadata": {},
   "source": [
    "## 자연어 처리에서 CNN\n",
    "- CNN을 이용한 문장 분류 아키텍처\n",
    "<img src='https://drive.google.com/uc?export=download&id=1Si0ma4WjKI0Hp02bTv7lizAYrTQtfQ7R' /><br>\n",
    "\n",
    "  - n개의 단어로 이루어진 리뷰 문장을 각 단어별로 k차원의 행벡터로 임베딩\n",
    "  - CNN 필터의 크기는 2, 3\n",
    "  - 필터 개수만큼의 Feature Map을 만들고 Max-Pooling 과정을 거쳐 클래스 개수(긍정 혹은 부정:2개)만큼의 스코어를 출력하는 네트워크 구조\n",
    "<br><br>\n",
    "- 자연어 처리에 사용되는 CNN\n",
    "<img src='https://drive.google.com/uc?export=download&id=1bxzttajTIt1cMFrNTlOVvwmUptfo9rZl' /><br>\n",
    "\n",
    "  - 이미지 처리에 사용되는 2D CNN과 달리 1D CNN 사용\n",
    "  - 1D CNN: 커널의 넓이를 문장 행렬에서의 임베딩 벡터의 차원과 동일하게 설정\n",
    "    - 예: 커널 사이즈 = 2 이면 높이가 2, 너비가 임베딩 벡터의 차원인 커널\n",
    "<br><br>\n",
    "- 논문: http://emnlp2014.org/papers/pdf/EMNLP2014181.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
